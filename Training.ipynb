{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFa1Or348PHl","executionInfo":{"status":"ok","timestamp":1718438948291,"user_tz":420,"elapsed":24787,"user":{"displayName":"Pujan Hiren Patel","userId":"09289011601235169294"}},"outputId":"e8de78c3-a17a-4bee-a8b2-c0390e6543e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"metadata":{},"colab":{"base_uri":"https://localhost:8080/"},"id":"igGYTLpo8Juy","executionInfo":{"status":"ok","timestamp":1718439001538,"user_tz":420,"elapsed":440,"user":{"displayName":"Pujan Hiren Patel","userId":"09289011601235169294"}},"outputId":"b88074ed-c8ce-41f3-ae32-07fe20e35134"},"outputs":[{"output_type":"stream","name":"stdout","text":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["# Imports\n","\n","# Creating Model\n","import os\n","import setuptools.dist\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.preprocessing import StandardScaler\n","from scipy.stats import multivariate_normal\n","import h5py\n","\n","# Setting Environment\n","# os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/opt/cuda'\n","print(tf.config.list_physical_devices('GPU'))\n","%matplotlib inline"]},{"cell_type":"code","execution_count":5,"metadata":{"metadata":{},"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"E73Q5KNI8Ju2","executionInfo":{"status":"ok","timestamp":1718439100765,"user_tz":420,"elapsed":96858,"user":{"displayName":"Pujan Hiren Patel","userId":"09289011601235169294"}},"outputId":"467bb25b-3c23-4b3b-b4c8-0b11866c5084"},"outputs":[{"output_type":"stream","name":"stdout","text":["(150985, 48, 48)\n","(150985, 5)\n"]},{"output_type":"execute_result","data":{"text/plain":["StandardScaler()"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":5}],"source":["# LOAD DATA\n","\n","file_path = '/content/drive/MyDrive/ResearchFiles/RHEED_4848_test6.h5' # Change to your PATH\n","\n","with h5py.File(file_path, 'r') as h5:\n","  spot = 'spot_2'\n","  g1 = np.array(h5['growth_1'][spot])\n","  g2 = np.array(h5['growth_2'][spot])\n","  g3 = np.array(h5['growth_3'][spot])\n","  g4 = np.array(h5['growth_4'][spot])\n","  g5 = np.array(h5['growth_5'][spot])\n","  g6 = np.array(h5['growth_6'][spot])\n","  g7 = np.array(h5['growth_7'][spot])\n","  g8 = np.array(h5['growth_8'][spot])\n","  g9 = np.array(h5['growth_9'][spot])\n","  g10 = np.array(h5['growth_10'][spot])\n","  g11 = np.array(h5['growth_11'][spot])\n","  g12 = np.array(h5['growth_12'][spot])\n","  images = np.concatenate((g1, g2, g3, g4, g5, g6, g7, g8, g9, g10, g11, g12))\n","\n","arr = []\n","for index, image in enumerate(images):\n","  temp = image.astype(np.float32)\n","  image_max = np.max(image)\n","  temp /= image_max\n","  arr.append(temp)\n","\n","images = np.array(arr)\n","\n","dataset = tf.data.Dataset.from_tensor_slices(images)\n","batch_size = 1000\n","batch_num = 151\n","data_loader = dataset.shuffle(buffer_size=len(images)).repeat().batch(batch_size).take(batch_num)\n","\n","images_array = np.load('/content/drive/MyDrive/ResearchFiles/images2.npy') # Change to your PATH\n","results_array = np.load('/content/drive/MyDrive/ResearchFiles/Results.npy') # Change to your PATH\n","print(images_array.shape)\n","print(results_array.shape)\n","\n","output_scaler = StandardScaler()\n","data=results_array\n","output_scaler.fit(data)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6bwyC4ED8Ju4","executionInfo":{"status":"ok","timestamp":1718439104952,"user_tz":420,"elapsed":231,"user":{"displayName":"Pujan Hiren Patel","userId":"09289011601235169294"}}},"outputs":[],"source":["# Gaussian Function (TENSORFLOW)\n","\n","print_example_guassian = 0\n","\n","# mean_x, mean_y, cov_x, cov_y, theta\n","def generate_guassian(batch, image_shape):\n","    batch_size = batch.shape[0]\n","    mean_x, mean_y, cov_x, cov_y, theta = tf.unstack(batch, axis=-1)\n","    x = tf.range(image_shape[1], dtype=tf.float32)[:, tf.newaxis]  # Create a column vector\n","    x = tf.tile(x, [1, image_shape[0]])  # Repeat along columns\n","\n","    y = tf.range(image_shape[0], dtype=tf.float32)[tf.newaxis, :]  # Create a row vector\n","    y = tf.tile(y, [image_shape[1], 1])  # Repeat along rows\n","\n","    x = tf.tile(tf.expand_dims(x, 0), [batch_size, 1, 1])\n","    y = tf.tile(tf.expand_dims(y, 0), [batch_size, 1, 1])\n","\n","    rota_matrix = tf.stack([tf.cos(theta), -tf.sin(theta), tf.sin(theta), tf.cos(theta)], axis=-1)\n","    rota_matrix = tf.reshape(rota_matrix, (batch_size, 2, 2))\n","\n","    xy = tf.stack([x - tf.reshape(mean_x, (-1, 1, 1)), y - tf.reshape(mean_y, (-1, 1, 1))], axis=-1)\n","    xy = tf.einsum('bijk,bkl->bijl', xy, rota_matrix)\n","\n","    img = tf.exp(-0.5 * (xy[:, :, :, 0]**2 / tf.reshape(cov_x, (-1, 1, 1))**2 + xy[:, :, :, 1]**2 / tf.reshape(cov_y, (-1, 1, 1))**2))\n","\n","    return tf.expand_dims(img, axis=1)\n","\n","if print_example_guassian:\n","    image_shape = (48, 48)\n","    batch = tf.convert_to_tensor([\n","        [19.2763, 24.8520, 11.2061,  6.8914,  0.7006]\n","        , [19.2763, 24.8520, 11.2061,  6.8914,  0.7006]\n","        , [19.2763, 24.8520, 11.2061,  6.8914,  50]\n","        , [19.2763, 24.8520, 11.2061,  6.8914,  0.7006]\n","        , [19.2763, 24.8520, 11.2061,  6.8914,  0.7006]\n","    ])\n","\n","    generated_imgs = generate_guassian(batch, image_shape)\n","    plt.imshow(tf.squeeze(generated_imgs[2]))\n","    plt.show()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"EnK5Hy7o8Ju4","executionInfo":{"status":"ok","timestamp":1718439113351,"user_tz":420,"elapsed":196,"user":{"displayName":"Pujan Hiren Patel","userId":"09289011601235169294"}}},"outputs":[],"source":["# Custom Loss Function (TENSORFLOW)\n","\n","print_example_loss = 0\n","\n","# @keras.saving.register_keras_serializable()\n","def custom_weighted_mse_loss(I, J, n):\n","  # Compute the weight\n","  W = tf.pow(I, n)\n","\n","  # Compute the squared differences\n","  squared_diffs = tf.pow(I - J, 2)\n","\n","  # Compute the weighted squared differences\n","  weighted_squared_diffs = W * squared_diffs\n","\n","  # Compute the loss\n","  loss = tf.reduce_mean(weighted_squared_diffs)\n","\n","  return loss\n","\n","if print_example_loss:\n","  I = tf.random.normal((16, 1, 48, 48))\n","  J = tf.random.normal((16, 1, 48, 48))\n","  n = 2\n","  loss = custom_weighted_mse_loss(I, J, n)\n","  print(\"Custom Weighted MSE Loss:\", loss.numpy())"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"uB4OjOYb8Ju5","executionInfo":{"status":"ok","timestamp":1718439116834,"user_tz":420,"elapsed":253,"user":{"displayName":"Pujan Hiren Patel","userId":"09289011601235169294"}}},"outputs":[],"source":["# Model Architecture\n","\n","model = tf.keras.Sequential(\n","    [\n","        layers.Conv2D(6, kernel_size=5, strides=1, padding='valid', data_format='channels_first')\n","        , layers.BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05)\n","        , layers.ReLU()\n","        , layers.MaxPool2D(pool_size=4, strides=4)\n","\n","        , layers.Conv2D(16, kernel_size=5, strides=1, padding='valid', data_format='channels_first')\n","        , layers.BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05)\n","        , layers.ReLU()\n","        , layers.MaxPool2D(pool_size=2, strides=2)\n","\n","        , layers.Flatten()\n","        , layers.Dense(98, activation='relu')\n","        , layers.Dense(52, activation='relu')\n","        , layers.Dense(5)\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{},"id":"tBYHQ4_A8Ju5"},"outputs":[],"source":["# Training Loop\n","train_model = 1\n","save_model = 0\n","load_model = 0\n","\n","if train_model:\n","    best_loss = float('inf')\n","    num_epochs = 200\n","    lr = 0.0001\n","    n = 1\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","    model.compile(optimizer='adam', loss=custom_weighted_mse_loss)\n","\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","\n","        if epoch % 10 == 0:\n","            n += 0.1\n","\n","        for images in tqdm(data_loader):\n","            images = tf.expand_dims(images, axis=1)\n","            with tf.GradientTape() as tape:\n","                embedding = model(images)\n","                unscaled_param = tf.constant(embedding * output_scaler.var_ ** 0.5 + output_scaler.mean_)\n","                final = generate_guassian(unscaled_param, (48,48))\n","                loss = custom_weighted_mse_loss(images, final, n)\n","            grads = tape.gradient(loss, model.trainable_variables)\n","            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","            running_loss += loss.numpy()\n","        average_loss = running_loss / len(data_loader)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss}\")\n","\n","if save_model:\n","    model.save(\"sequential.keras\")\n","if load_model:\n","    model = keras.models.load_model('sequential.keras')\n","\n","model.summary()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}